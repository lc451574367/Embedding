this is the bert pre-trained model: layer=2, Hidden = 128, uncased.
