this is the bert pre-trained model: layer=10, Hidden = 128, uncased.
