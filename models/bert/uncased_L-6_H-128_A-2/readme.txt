this is the bert pre-trained model: layer=6, Hidden = 128, uncased.
