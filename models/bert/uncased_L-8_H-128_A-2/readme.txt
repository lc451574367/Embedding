this is the bert pre-trained model: layer=8, Hidden = 128, uncased.
